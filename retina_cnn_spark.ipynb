{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008aa828-9f7a-4fa3-8fbe-5cea95ab6621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://hadoop1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://192.168.13.119:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RetinaCNN_SparkProject</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1658379b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spark Setup\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RetinaCNN_SparkProject\") \\\n",
    "    .master(\"spark://192.168.13.119:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febf904c-7721-457d-a21e-7ae9340cef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "\n",
      "Spark executors: [Lorg.apache.spark.SparkExecutorInfo;@7f26aafc\n"
     ]
    }
   ],
   "source": [
    "#Spark Verification\n",
    "\n",
    "df = spark.range(0, 20)\n",
    "df.show()\n",
    "print(\"Spark executors:\", spark.sparkContext._jsc.sc().statusTracker().getExecutorInfos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "694fcd82-1194-406d-8e8c-75176a3218cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a992591d-95a7-4c73-87f9-733ef2033db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retinopathy Grade\n",
    "\n",
    "label_to_grade = {\n",
    "    0: \"No DR\",\n",
    "    1: \"Mild\",\n",
    "    2: \"Moderate\",\n",
    "    3: \"Severe\",\n",
    "    4: \"Proliferative DR\"\n",
    "}\n",
    "\n",
    "grade_to_label = {v: k for k, v in label_to_grade.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cafe438-74cd-4e76-b7f7-7df5a991ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Loader\n",
    "\n",
    "class RetinaDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_col = \"Image name\"\n",
    "        self.label_col = \"Retinopathy grade\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx][self.image_col]\n",
    "        label = int(self.df.iloc[idx][self.label_col])\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "925e676e-cbe3-48fd-98ec-4a5721313e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Transform (For ResNet)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "097dec31-f47e-4ad4-ad37-50a8a55f4ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset and Loaders\n",
    "\n",
    "base_dir = Path(\"/home/sat3812/cnn_project\")\n",
    "\n",
    "train_csv = base_dir/\"train\"/\"annotations.csv\"\n",
    "valid_csv = base_dir/\"valid\"/\"annotations.csv\"\n",
    "test_csv  = base_dir/\"test\"/\"annotations.csv\"\n",
    "\n",
    "train_imgs = base_dir/\"train\"/\"images\"\n",
    "valid_imgs = base_dir/\"valid\"/\"images\"\n",
    "test_imgs  = base_dir/\"test\"/\"images\"\n",
    "\n",
    "train_dataset = RetinaDataset(train_csv, train_imgs, train_transform)\n",
    "valid_dataset = RetinaDataset(valid_csv, valid_imgs, test_transform)\n",
    "test_dataset  = RetinaDataset(test_csv,  test_imgs,  test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9a3b3fb-38a5-490e-b43f-470c7f410b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/sat3812/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "#ResNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "#EarlyLayerFreezing- Important for Medical Images\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 5)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52df4c4d-9f5a-4cd6-ae05-ead68e50b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opt- Adam knows best &Loss- Important to penalize misclassification\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccb54f72-fc02-4b5a-a7d8-896d6eade2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, epochs=20):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss /= total\n",
    "\n",
    "#Validation\n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        correct_v = 0\n",
    "        total_v = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                valid_loss += loss.item() * images.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct_v += (preds == labels).sum().item()\n",
    "                total_v += labels.size(0)\n",
    "\n",
    "        valid_acc = correct_v / total_v\n",
    "        valid_loss /= total_v\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Acc={train_acc:.4f}, Valid Acc={valid_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76333260-0502-4ccd-888d-6deabb05b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc=0.5276, Valid Acc=0.5752\n",
      "Epoch 2: Train Acc=0.5732, Valid Acc=0.5664\n",
      "Epoch 3: Train Acc=0.5701, Valid Acc=0.5870\n",
      "Epoch 4: Train Acc=0.5840, Valid Acc=0.5959\n",
      "Epoch 5: Train Acc=0.5935, Valid Acc=0.6047\n",
      "Epoch 6: Train Acc=0.6018, Valid Acc=0.5811\n",
      "Epoch 7: Train Acc=0.5992, Valid Acc=0.5811\n",
      "Epoch 8: Train Acc=0.5954, Valid Acc=0.6106\n",
      "Epoch 9: Train Acc=0.6214, Valid Acc=0.6165\n",
      "Epoch 10: Train Acc=0.6024, Valid Acc=0.5959\n",
      "Epoch 11: Train Acc=0.6170, Valid Acc=0.6313\n",
      "Epoch 12: Train Acc=0.6126, Valid Acc=0.6224\n",
      "Epoch 13: Train Acc=0.6113, Valid Acc=0.6283\n",
      "Epoch 14: Train Acc=0.6138, Valid Acc=0.5959\n",
      "Epoch 15: Train Acc=0.6265, Valid Acc=0.6254\n",
      "Epoch 16: Train Acc=0.6208, Valid Acc=0.6047\n",
      "Epoch 17: Train Acc=0.6252, Valid Acc=0.5841\n",
      "Epoch 18: Train Acc=0.6170, Valid Acc=0.6224\n",
      "Epoch 19: Train Acc=0.6107, Valid Acc=0.6047\n",
      "Epoch 20: Train Acc=0.6024, Valid Acc=0.6047\n"
     ]
    }
   ],
   "source": [
    "#Model Training Day\n",
    "\n",
    "train_model(model, train_loader, valid_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32525071-7f08-4609-a7aa-da5ded804987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[173   0   3   2   0]\n",
      " [ 43   0   1   0   0]\n",
      " [ 45   0  11  20   0]\n",
      " [  5   0   3  15   2]\n",
      " [  5   0   0   9   1]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            Mild       0.00      0.00      0.00        44\n",
      "        Moderate       0.61      0.14      0.23        76\n",
      "           No DR       0.64      0.97      0.77       178\n",
      "Proliferative DR       0.33      0.07      0.11        15\n",
      "          Severe       0.33      0.60      0.42        25\n",
      "\n",
      "        accuracy                           0.59       338\n",
      "       macro avg       0.38      0.36      0.31       338\n",
      "    weighted avg       0.51      0.59      0.49       338\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sat3812/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/sat3812/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/sat3812/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Eval\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    [label_to_grade[l] for l in all_labels],\n",
    "    [label_to_grade[p] for p in all_preds],\n",
    "))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Spark Cluster)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
